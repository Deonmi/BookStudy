# 第10章_人工神经网络简介

[TOC]

**参考书**

《机器学习实战——基于Scikit-Learn和TensorFlow》

**工具**

python3.5.1，Jupyter Notebook, Pycharm

## 感知器

- 《行为的组织》，1949，Donald Hebb：如果一个生物神经元总是出发另外的神经元，那么这两个神经元之间的连接就会变得更强。
- Siegrid Lowel：同时处于激活状态的细胞时会连在一起的。
- Hebb定律（又叫Hebbian学习）：当两个神经元有相同的输出时，它们之间的连接权重就会增强。
- 感知器收敛定理（Rosenblatt）：如果训练实例是线性可分的，这个算法会收敛到一个解。

## 线性阈值单元（LTU）

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron

iris = load_iris()
X = iris.data[:, (2, 3)]
y = (iris.target == 0).astype(np.int)
per_clf = Perceptron(random_state=42)
per_clf.fit(X, y)

y_pred = per_clf.predict([[2, 0.5]])
print(y_pred)
```

- 事实上，在sklearn中，Perceptron类的行为等同于使用以下超参数的**SGDClassifier**：

  ```python
  loss="perceptron", learning_rate="constant", eta0=1（学习速率）, penalty=None（不做正则化）
  ```

- 注意和逻辑回归分类器相反，感知器不输出某个类的概率，它只能根据一个固定的阈值来做预测。这也是更应该使用逻辑回归而不是感知器的一个原因。

- 感知器无法处理一些很微小的问题，比如异或分类问题（XOR），不过事实证明感知器的一些限制可以通过多层感知器来解决（Multi-Layer Perceptron，MLP）

## 多层感知器和反向传播

- 如果一个ANN有2个及以上的隐藏层，则被称为深度神经网络（DNN）。
- 反向自动微分的梯度下降法：对于每个训练实例，反向传播算法先做一次预测（**正向过程**），度量误差，然后反向的遍历每个层次来度量每个连接的误差贡献度（**反向过程**），最后再微调每个连接的权重来降低误差（**梯度下降**）。

## 使用TensorFlow的高级API来训练MLP

- 用DNNClassifier类来训练一个有着任意数量隐藏层，并包含一个用来计算类别概率的sofmax输出层的神经网络。

  ```python
  from tensorflow.examples.tutorials.mnist import input_data
  import tensorflow as tf
  
  mnist = input_data.read_data_sets("D:/李添的数据哦！！！/BookStudy/book4/MNIST_data/MNIST_data/")
  
  X_train = mnist.train.images
  X_test = mnist.test.images
  y_train = mnist.train.labels.astype("int")
  y_test = mnist.test.labels.astype("int")
  
  config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config
  
  feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)
  dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=10,
                                           feature_columns=feature_cols, config=config)
  dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1
  dnn_clf.fit(X_train, y_train, batch_size=50, steps=40000)
  ```
  
- 模型评估

  ```python
  from sklearn.metrics import accuracy_score
  
  y_pred = dnn_clf.predict(X_test)
  accuracy_score(y_test, y_pred['classes'])
  ```

  ```python
  from sklearn.metrics import log_loss
  
  y_pred_proba = y_pred['probabilities']
  log_loss(y_test, y_pred_proba)
  ```

- 库还包含了一些方便的函数来评估模型：

  ```python
  dnn_clf.score(X_test, y_test)
  ```

## 使用纯TensorFlow训练DNN



------

我的CSDN：https://blog.csdn.net/qq_21579045

我的博客园：https://www.cnblogs.com/lyjun/

我的Github：https://github.com/TinyHandsome

纸上得来终觉浅，绝知此事要躬行~

欢迎大家过来OB~

by 李英俊小朋友