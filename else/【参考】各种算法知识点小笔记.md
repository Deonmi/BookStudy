# 小笔记

- [机器学习特征选择的方法](https://www.cnblogs.com/bonelee/p/8632866.html)
- [典型推荐算法总结](https://blog.csdn.net/u011095110/article/details/84403564)
- [机器学习算法总结](https://www.cnblogs.com/jiangxinyang/p/9217424.html)
- [XGBoost](https://www.hrwhisper.me/machine-learning-xgboost/)
- [GBDT梯度提升树](https://blog.csdn.net/weixin_42933718/article/details/88421574#GBDT_2)
- [机器学习-树模型理论（GDBT，xgboost，lightBoost，随机森林）](https://www.cnblogs.com/onemorepoint/p/9799124.html)
- [浅谈机器学习方法](https://www.cnblogs.com/flippedkiki/p/7209076.html?utm_source=itdadao&utm_medium=referral)
- [Bagging和Boosting 概念及区别](https://www.cnblogs.com/gczr/p/7097442.html)
- [机器学习面试问题大概梳理](https://www.cnblogs.com/gczr/p/6829176.html)
- [Keras学习率调整](https://www.cnblogs.com/nxf-rabbit75/p/10564888.html)
- [网格搜索参数详解](https://blog.csdn.net/CherDW/article/details/54970366)
- [多标签分类、多任务分类、多输出回归概念](https://blog.csdn.net/zb1165048017/article/details/77882600)
- [详解机器学习中的熵、条件熵、相对熵和交叉熵](https://www.cnblogs.com/kyrieng/p/8694705.html)

机器学习实战参考资料：

- [随机森林代码与调参](https://www.jianshu.com/p/5354f2a42a73)，[随机森林的参数说明](https://www.cnblogs.com/gczr/p/7141712.html)
- [逻辑回归的参数说明](https://blog.csdn.net/sun_shengyun/article/details/53811483)，[逻辑回归调参](https://www.jianshu.com/p/99ceb640efc5)，[逻辑回归代码与调参](https://www.cnblogs.com/onemorepoint/p/9486998.html?utm_source=debugrun&utm_medium=referral)
- [正负样本不均衡的解决办法](https://blog.csdn.net/jemila/article/details/77992967)

Java面试算法必须掌握：

- [Java面试-排序算法](https://blog.csdn.net/weixin_41835916/article/details/81661314)
- [Java面试-查找算法](https://blog.csdn.net/babylorin/article/details/67638156)